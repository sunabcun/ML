---
title: 'compgen2021: Week 1 exercises'
author: "Yuna Son"
date: "8/7/2021"
output:
  pdf_document: default
  pdf: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercises for Week1

## Statistics for genomics 

### How to summarize collection of data points: The idea behind statistical distributions

1. Calculate the means and variances 
of the rows of the following simulated data set, and plot the distributions
of means and variances using `hist()` and `boxplot()` functions. [Difficulty: **Beginner/Intermediate**]  
```{r}
set.seed(100)
#sample data matrix from normal distribution
gset=rnorm(600,mean=200,sd=70)
data=matrix(gset,ncol=6)
A_1 <- matrix(NA,100,2)
for (i in 1:100){
A_1[i,] <- c(mean(data[i,]), sd(data[i,])^2)
}

```

```{r}
# Plotting histograms and boxplots
par(mfrow = c(1,2))
hist(A_1[,1], col = "cornflowerblue", border="white",main = "Histogram of means")
hist(A_1[,2], col = "cornflowerblue", border="white",main = "Histogram of variances")
par(mfrow = c(1,2))
boxplot(A_1[,1], main = "Boxplot of means")
boxplot(A_1[,2],main = "Boxplot of variances")

```

2. Using the data generated above, calculate the standard deviation of the
distribution of the means using the `sd()` function. Compare that to the expected
standard error obtained from the central limit theorem keeping in mind the
population parameters were  $\sigma=70$ and $n=6$. How does the estimate from the random samples change if we simulate more data with
`data=matrix(rnorm(6000,mean=200,sd=70),ncol=6)`? [Difficulty: **Beginner/Intermediate**] 
```{r}
# Calculate the standard deviation of the distribution of the means
sd(A_1[,1])
# Compare that to the expected standard error obtained from the central limit theorem.
70/sqrt(6)

# Do simulation with more samples
data2=matrix(rnorm(6000,mean=200,sd=70),ncol=6)
A_2 <- matrix(NA,100,2)
for (i in 1:100){
  A_2[i,] <- c(mean(data2[i,]), sd(data2[i,])^2)
}
sd(A_2[,1])

```
When we do more simulation with more data, the standard deviation of the distribution of the means reduces.


3. Simulate 30 random variables using the `rpois()` function. Do this 1000 times and calculate the mean of each sample. Plot the sampling distributions of the means
using a histogram. Get the 2.5th and 97.5th percentiles of the
distribution. [Difficulty: **Beginner/Intermediate**] 
```{r}
# Generate 30 random variables from a Poission distribution with mean 1 (1000 times)
library(mosaic)
set.seed(1000)
sample = rpois(30, 1)
my_pois = do(1000) * mean(resample(sample))


# get percentiles
q = quantile(my_pois[,1], p = c(0.025, 0.975))
q

# Plotting histograms
hist(my_pois[,1], col = "cornflowerblue", border="white", xlab = "sample means", main = "Histogram of means")
abline(v=c(q[1], q[2] ),col="red")
text(x=q[1], y = 200, round(q[1], 3), adj = c(1, 0))
text(x=q[2],y=200,round(q[2],3),adj=c(0,0))
```
4. Use the `t.test()` function to calculate confidence intervals
of the mean on the first random sample `pois1` simulated from the `rpois()` function below. [Difficulty: **Intermediate**] 
```{r}
#HINT
set.seed(100)
#sample 30 values from poisson dist with lamda paramater =30
pois1=rpois(30,lambda=5)
t.test(pois1)
```
95 percent confidence interval is (4.362104, 5.504563).


5. Use the bootstrap confidence interval for the mean on `pois1`. [Difficulty: **Intermediate/Advanced**] 
```{r}
pois1=rpois(30,lambda=5)
# Simulate 100 times
my_pois = do(100) * mean(resample(pois1))

# get percentiles
q = quantile(my_pois[,1], p = c(0.025, 0.975))
q


```

### How to test for differences in samples
1. Test the difference of means of the following simulated genes
using the randomization, `t-test()`, and `wilcox.test()` functions.
Plot the distributions using histograms and boxplots. [Difficulty: **Intermediate/Advanced**] 
```{r}
set.seed(101)
gene1=rnorm(30,mean=4,sd=3)
gene2=rnorm(30,mean=3,sd=3)

org.diff = mean(gene1) - mean(gene2)
gene.df = data.frame(exp=c(gene1, gene2),
                     group = c(rep("gene1", 30), rep("control", 30)))
exp.gene <- do(1000) * diff(mosaic::mean(exp ~ shuffle(group), data = gene.df))

hist(exp.gene[,1],xlab="means distribution",
     xlim=c(-2,2),col="cornflowerblue",border="white")


abline(v=quantile(exp.gene[,1],0.95),col="red")
abline(v=org.diff,col="blue" )
text(x=quantile(exp.gene[,1],0.95),y=200,"0.05",adj=c(1,0),col="red")
text(x=org.diff,y=200,"org. diff.",adj=c(1,0),col="blue")

boxplot(exp.gene[,1],xlab="means distribution")

t.test(gene1, gene2)

wilcox.test(gene1, gene2)
```



2. Test the difference of the means of the following simulated genes
using the randomization, `t-test()` and `wilcox.test()` functions.
Plot the distributions using histograms and boxplots. [Difficulty: **Intermediate/Advanced**] 
```{r}
set.seed(100)
gene1=rnorm(30,mean=4,sd=2)
gene2=rnorm(30,mean=2,sd=2)
org.diff = mean(gene1) - mean(gene2)
gene.df = data.frame(exp=c(gene1, gene2),
                     group = c(rep("gene1", 30), rep("control", 30)))
exp.gene <- do(1000) * diff(mosaic::mean(exp ~ shuffle(group), data = gene.df))

hist(exp.gene[,1],xlab="means distribution",
     xlim=c(-2,2),col="cornflowerblue",border="white")


abline(v=quantile(exp.gene[,1],0.95),col="red")
abline(v=org.diff,col="blue" )
text(x=quantile(exp.gene[,1],0.95),y=200,"0.05",adj=c(1,0),col="red")
text(x=org.diff,y=200,"org. diff.",adj=c(1,0),col="blue")

boxplot(exp.gene[,1],xlab="means distribution")

t.test(gene1, gene2)

wilcox.test(gene1, gene2)
```


3. We need an extra data set for this exercise. Read the gene expression data set as follows:
`gexpFile=system.file("extdata","geneExpMat.rds",package="compGenomRData") data=readRDS(gexpFile)`. The data has 100 differentially expressed genes. The first 3 columns are the test samples, and the last 3 are the control samples. Do 
a t-test for each gene (each row is a gene), and record the p-values.
Then, do a moderated t-test, as shown in section "Moderated t-tests" in this chapter, and record 
the p-values. Make a p-value histogram and compare two approaches in terms of the number of significant tests with the $0.05$ threshold.
On the p-values use FDR (BH), Bonferroni and q-value adjustment methods.
Calculate how many adjusted p-values are below 0.05 for each approach.
[Difficulty: **Intermediate/Advanced**] 


```{r}
gexpFile=system.file("extdata","geneExpMat.rds",package="compGenomRData")
data=readRDS(gexpFile)

# t.tests
group1=1:3
group2=4:6
n1=3
n2=3
dx=rowMeans(data[,group1])-rowMeans(data[,group2])

require(matrixStats)

# get the esimate of pooled variance 
stderr = sqrt( (rowVars(data[,group1])*(n1-1) + 
       rowVars(data[,group2])*(n2-1)) / (n1+n2-2) * ( 1/n1 + 1/n2 ))

# do the shrinking towards median
mod.stderr = (stderr + median(stderr)) / 2 # moderation in variation

# esimate t statistic with moderated variance
t.mod <- dx / mod.stderr

# calculate P-value of rejecting null 
p.mod = 2*pt( -abs(t.mod), n1+n2-2 )

# esimate t statistic without moderated variance
t = dx / stderr

# calculate P-value of rejecting null 
p = 2*pt( -abs(t), n1+n2-2 )

par(mfrow=c(1,2))
hist(p,col="cornflowerblue",border="white",main="",xlab="P-values t-test")
mtext(paste("signifcant tests:",sum(p<0.05))  )
hist(p.mod,col="cornflowerblue",border="white",main="",
     xlab="P-values mod. t-test")
mtext(paste("signifcant tests:",sum(p.mod<0.05))  )
```
moderated t-test has more stringent results.

```{r}
library(qvalue)

qvalues <- qvalue(p)$q
bonf.pval=p.adjust(p,method ="bonferroni")
fdr.adj.pval=p.adjust(p,method ="fdr")

plot(p,qvalues,pch=19,ylim=c(0,1),
     xlab="raw P-values",ylab="adjusted P-values")
points(p,bonf.pval,pch=19,col="red")
points(p,fdr.adj.pval,pch=19,col="blue")
legend("bottomright",legend=c("q-value","FDR (BH)","Bonferroni"),
       fill=c("black","blue","red"))
```
Bonferroni showed the most stringent p-values. 


### Relationship between variables: Linear models and correlation

Below we are going to simulate X and Y values that are needed for the 
rest of the exercise.

1. Run the code then fit a line to predict Y based on X. [Difficulty:**Intermediate**] 
```{r}
# set random number seed, so that the random numbers from the text
# is the same when you run the code.
set.seed(32)
# get 50 X values between 1 and 100
x = runif(50,1,100)
# set b0,b1 and variance (sigma)
b0 = 10
b1 = 2
sigma = 20
# simulate error terms from normal distribution
eps = rnorm(50,0,sigma)
# get y values from the linear equation and addition of error terms
y = b0 + b1*x+ eps

mod1=lm(y~x)

coef(mod1)

```


2. Plot the scatter plot and the fitted line. [Difficulty:**Intermediate**] 
```{r}
# plot the data points
plot(x,y,pch=20,
     ylab="Y",xlab="X")
# plot the linear fit
abline(mod1,col="blue")
```


3. Calculate correlation and R^2. [Difficulty:**Intermediate**] 
```{r}
cor(x, y, method = "pearson")
summary(mod1)$r.squared
```


4. Run the `summary()` function and 
try to extract P-values for the model from the object
returned by `summary`. See `?summary.lm`. [Difficulty:**Intermediate/Advanced**] 
```{r}
with(summary(mod1), pf(fstatistic[1],fstatistic[2],fstatistic[3],lower.tail=F))
```


5. Plot the residuals vs. the fitted values plot, by calling the `plot()` 
function with `which=1` as the second argument. First argument
is the model returned by `lm()`. [Difficulty:**Advanced**] 

```{r}

# Plot residual vs. fitted
plot(mod1, which = 1)

```


6. For the next exercises, read the data set histone modification data set. Use the following to get the path to the file:
```
hmodFile=system.file("extdata",
                    "HistoneModeVSgeneExp.rds",
                     package="compGenomRData")
```
There are 3 columns in the dataset. These are measured levels of H3K4me3,
H3K27me3 and gene expression per gene. Once you read in the data, plot the scatter plot for H3K4me3 vs. expression. [Difficulty:**Beginner**] 

```{r}
hmodFile=system.file("extdata",
                    "HistoneModeVSgeneExp.rds",
                     package="compGenomRData")
data=readRDS(hmodFile)

plot(data$H3k4me3, data$measured_log2, xlab="Measured levels of H3K4me3", ylab="Expression")
```

7. Plot the scatter plot for H3K27me3 vs. expression. [Difficulty:**Beginner**] 
```{r}
plot(data$H3k27me3, data$measured_log2, xlab="Measured levels of H3K27me3", ylab="Expression")
```


8. Fit the model for prediction of expression data using: 1) Only H3K4me3 as explanatory variable, 2) Only H3K27me3 as explanatory variable, and 3) Using both H3K4me3 and H3K27me3 as explanatory variables. Inspect the `summary()` function output in each case, which terms are significant. [Difficulty:**Beginner/Intermediate**] 

```{r}
fit1 <- lm(measured_log2 ~ H3k4me3, data = data)
summary(fit1)
```

```{r}
fit2 <- lm(measured_log2 ~ H3k27me3, data = data)
summary(fit2)
```
H3K4me3 showed better correlation than H3K27me3 only fitted model by R-squared values (H3K4me3 is closer to 1) and F statistics (higher values in H3K4me3).

```{r}
fit3 <- lm(measured_log2 ~ H3k4me3 + H3k27me3, data = data)
summary(fit3)
```

10. Is using H3K4me3 and H3K27me3 better than the model with only H3K4me3? [Difficulty:**Intermediate**] 

Multiple regression model shows lower F-statistic than H3K4me3 only model. So, Multiple regression model may not be better to reject the null hypothesis. 







